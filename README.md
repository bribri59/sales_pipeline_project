# Sales Pipeline ‚Äì Databricks (TP Industrialisation Spark)

## üéØ Objectif du projet

Ce projet a pour objectif d‚Äôindustrialiser un traitement Spark d√©velopp√© initialement sous forme de notebooks Databricks.

Il impl√©mente un pipeline de traitement des donn√©es de ventes d‚Äôune entreprise de retail, en suivant l‚Äôarchitecture **M√©daillon** :

- **Bronze** : ingestion des donn√©es brutes des boutiques
- **Silver** : nettoyage, normalisation et enrichissement des donn√©es
- **Gold** : calcul des indicateurs m√©tiers (chiffre d‚Äôaffaires, classements produits)

Le projet est structur√© comme une application Python packag√©e, ex√©cutable et maintenable.

---

## üß± Architecture du pipeline


- **Bronze** : lecture des fichiers CSV mensuels par boutique et stockage en tables Delta
- **Silver** : harmonisation des sch√©mas, traduction des libell√©s, enrichissement g√©ographique
- **Gold** : agr√©gations et calcul des KPI en EUR

---

## ‚ñ∂Ô∏è Ex√©cution du pipeline

Le pipeline est ex√©cut√© via le script `main.py`.

Un fichier de configuration YAML est utilis√© pour d√©finir :
- les chemins de donn√©es,
- les noms de bases,
- les taux de conversion.

### Exemple d‚Äôex√©cution depuis Databricks (notebook)

```python
from main import main

main(dbutils=dbutils)
